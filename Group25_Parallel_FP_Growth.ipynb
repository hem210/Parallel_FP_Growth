{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Parallel FP-Growth using Map-Reduce Approach"
      ],
      "metadata": {
        "id": "4JJQ6T-YuRYb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Installing and Importing Libraries"
      ],
      "metadata": {
        "id": "GpAGKaSPW8wg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --quiet mrjob==0.7.4"
      ],
      "metadata": {
        "id": "JjDk9IT1KhDd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6130fd27-cdc8-4d57-ba3b-3b3ef72c386d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/439.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.8/439.6 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m430.1/439.6 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m439.6/439.6 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --quiet mlxtend --upgrade"
      ],
      "metadata": {
        "id": "ovRvDEFlrkVE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85e95392-4f6f-4181-cf5e-949063a5acfe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.4 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.1/1.4 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.5/1.4 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.4 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tvWKT2TBx5pu"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import re\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from prettytable import PrettyTable"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "rBFPrQ0l0CYI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6559759-8383-4bed-c614-4a01ef7ab9ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Filtering out Transactions from the dataset"
      ],
      "metadata": {
        "id": "v-hHg_kjClNs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "groceries = pd.read_csv(\"/content/drive/MyDrive/BDP_Project/Retail_Transactions_Dataset.csv\")"
      ],
      "metadata": {
        "id": "w5Fi13XPC4Uu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import ast\n",
        "\n",
        "groceries['Product'] = groceries['Product'].apply(ast.literal_eval)\n",
        "\n",
        "all_transactions = groceries['Product'].tolist()  # a list of list of strings containing transactions\n",
        "\n",
        "print(all_transactions[0:5])"
      ],
      "metadata": {
        "id": "STLH3cZTDb_o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf70834b-1796-425c-e399-a7182c19f84b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['Hair Gel'], ['Tuna', 'Bread', 'Tissues', 'Trash Bags'], ['Jam', 'Soap', 'Ketchup'], ['BBQ Sauce'], ['Hand Sanitizer', 'Bread', 'Extension Cords', 'Ice Cream', 'Hand Sanitizer']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Saving the transactions dataset in a file `all_transactions.csv`"
      ],
      "metadata": {
        "id": "LI5mzOaIszsF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(all_transactions)\n",
        "# df.head()\n",
        "\n",
        "df.to_csv('/content/drive/MyDrive/BDP_Project/all_transactions.csv', index=False, header=False)"
      ],
      "metadata": {
        "id": "YP06Wsg2gd2a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Parallel Counting"
      ],
      "metadata": {
        "id": "59qyWLy0iXnz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The below given code calculates individual frequencies of all the items."
      ],
      "metadata": {
        "id": "XxtUZFa0tE20"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%file parallel_count.py\n",
        "from mrjob.job import MRJob\n",
        "import csv\n",
        "\n",
        "class ItemFrequency(MRJob):\n",
        "\n",
        "    def mapper(self, _, line):\n",
        "        # Convert string back to list\n",
        "        items = list(csv.reader([line]))[0]\n",
        "\n",
        "        # Yield each item\n",
        "        for item in items:\n",
        "            yield (item, 1)\n",
        "\n",
        "    def reducer(self, key, values):\n",
        "        # Sum up the counts for each item\n",
        "        yield (key, sum(values))\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    ItemFrequency.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aMPA6M2TKUOw",
        "outputId": "f15a8115-e593-4bb0-e632-0c09643c5b4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing parallel_count.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python parallel_count.py \"/content/drive/MyDrive/BDP_Project/all_transactions.csv\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "so4X0GLmNA03",
        "outputId": "55b0cb6e-7f57-4eea-c1c4-e5e62dab879f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No configs found; falling back on auto-configuration\n",
            "No configs specified for inline runner\n",
            "Creating temp directory /tmp/parallel_count.root.20231123.052529.826287\n",
            "Running step 1 of 1...\n",
            "job output is in /tmp/parallel_count.root.20231123.052529.826287/output\n",
            "Streaming final output from /tmp/parallel_count.root.20231123.052529.826287/output...\n",
            "\"Beef\"\t1132\n",
            "\"Bread\"\t1093\n",
            "\"Broom\"\t1111\n",
            "\"Butter\"\t1160\n",
            "\"Canned Soup\"\t1031\n",
            "\"Carrots\"\t1110\n",
            "\"Cereal Bars\"\t1060\n",
            "\"Cereal\"\t1094\n",
            "\"Cheese\"\t1090\n",
            "\"Chicken\"\t1063\n",
            "\"Chips\"\t1080\n",
            "\"Cleaning Rags\"\t1088\n",
            "\"Cleaning Spray\"\t1111\n",
            "\"Coffee\"\t1067\n",
            "\"Deodorant\"\t1152\n",
            "\"Diapers\"\t1130\n",
            "\"Dish Soap\"\t1138\n",
            "\"Dishware\"\t1095\n",
            "\"Dustpan\"\t1078\n",
            "\"Eggs\"\t1096\n",
            "\"Extension Cords\"\t1129\n",
            "\"Feminine Hygiene Products\"\t1031\n",
            "\"Garden Hose\"\t1164\n",
            "\"Hair Gel\"\t1124\n",
            "\"Hand Sanitizer\"\t1072\n",
            "\"Honey\"\t1111\n",
            "\"Ice Cream\"\t1089\n",
            "\"Insect Repellent\"\t1079\n",
            "\"Iron\"\t1042\n",
            "\"Ironing Board\"\t1148\n",
            "\"Jam\"\t1085\n",
            "\"Ketchup\"\t1096\n",
            "\"Laundry Detergent\"\t1106\n",
            "\"Lawn Mower\"\t1093\n",
            "\"Light Bulbs\"\t1104\n",
            "\"Mayonnaise\"\t1057\n",
            "\"Milk\"\t1102\n",
            "\"Mop\"\t1102\n",
            "\"Mustard\"\t1106\n",
            "\"Olive Oil\"\t1147\n",
            "\"Onions\"\t1155\n",
            "\"Orange\"\t1046\n",
            "\"Pancake Mix\"\t1068\n",
            "\"Paper Towels\"\t1072\n",
            "\"Pasta\"\t1077\n",
            "\"Peanut Butter\"\t1133\n",
            "\"Pickles\"\t1134\n",
            "\"Plant Fertilizer\"\t1102\n",
            "\"Potatoes\"\t1109\n",
            "\"Power Strips\"\t1101\n",
            "\"\"\t59809\n",
            "\"Air Freshener\"\t1099\n",
            "\"Apple\"\t1074\n",
            "\"BBQ Sauce\"\t1082\n",
            "\"Baby Wipes\"\t1084\n",
            "\"Banana\"\t1093\n",
            "\"Bath Towels\"\t1115\n",
            "\"Razors\"\t1100\n",
            "\"Rice\"\t1108\n",
            "\"Salmon\"\t1116\n",
            "\"Shampoo\"\t1121\n",
            "\"Shaving Cream\"\t1145\n",
            "\"Shower Gel\"\t1066\n",
            "\"Shrimp\"\t1106\n",
            "\"Soap\"\t1101\n",
            "\"Soda\"\t1149\n",
            "\"Spinach\"\t1146\n",
            "\"Sponges\"\t1172\n",
            "\"Syrup\"\t1083\n",
            "\"Tea\"\t1059\n",
            "\"Tissues\"\t1097\n",
            "\"Toilet Paper\"\t1107\n",
            "\"Tomatoes\"\t1095\n",
            "\"Toothbrush\"\t1085\n",
            "\"Toothpaste\"\t2088\n",
            "\"Trash Bags\"\t1128\n",
            "\"Trash Cans\"\t1104\n",
            "\"Tuna\"\t1151\n",
            "\"Vacuum Cleaner\"\t1022\n",
            "\"Vinegar\"\t1101\n",
            "\"Water\"\t1116\n",
            "\"Yogurt\"\t1115\n",
            "Removing temp directory /tmp/parallel_count.root.20231123.052529.826287...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Constructing FList and GList using Parallel Counting\n",
        "\n",
        "The below given code calculates the FList using Parallel Counting, and using the FList, a GList is constructed."
      ],
      "metadata": {
        "id": "-wyrRMs3ieDp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%file parallel_count.py\n",
        "\n",
        "from mrjob.job import MRJob\n",
        "from mrjob.step import MRStep\n",
        "import re\n",
        "import csv\n",
        "\n",
        "class ParallelCount1(MRJob):\n",
        "\n",
        "    def mapper(self, _, line):\n",
        "        items = list(csv.reader([line]))[0]\n",
        "        for item in items:\n",
        "            yield (item, 1)\n",
        "\n",
        "    def reducer(self, item, counts):\n",
        "        yield None, (item, sum(counts))\n",
        "\n",
        "    def mapper_init_1(self):\n",
        "        self.g = []\n",
        "\n",
        "    def mapper_1(self, _, item_freq):\n",
        "        item, frequency = item_freq\n",
        "        self.g.append((item, frequency))\n",
        "        yield None, (item, frequency)\n",
        "\n",
        "    def reducer_init_1(self):\n",
        "        self.flist = []\n",
        "\n",
        "    def reducer_1(self, _, item_freqs):\n",
        "        for item, frequency in item_freqs:\n",
        "            self.flist.append((item, frequency))\n",
        "        yield None, self.flist\n",
        "\n",
        "    def mapper_init_2(self):\n",
        "        self.glist = []\n",
        "        self.Q = 6\n",
        "\n",
        "    def mapper_2(self, _, flist):\n",
        "        c = 0\n",
        "        a = []\n",
        "        for item, frequency in flist:\n",
        "            if c < self.Q and item.strip(\"', \"):  # Exclude empty items\n",
        "                a.append(item)\n",
        "            else:\n",
        "                if c % self.Q == 0:\n",
        "                    self.glist.append([int(c / self.Q), a])\n",
        "                    a = []\n",
        "                    a.append(item)\n",
        "                else:\n",
        "                    a.append(item)\n",
        "            c += 1\n",
        "        if len(a) != 0:\n",
        "            self.glist.append([int(c / self.Q) + 1, a])\n",
        "\n",
        "        for group in self.glist:\n",
        "            yield group[0], group[1]\n",
        "\n",
        "    def steps(self):\n",
        "        return [\n",
        "            MRStep(mapper=self.mapper, reducer=self.reducer),\n",
        "            MRStep(mapper_init=self.mapper_init_1, mapper=self.mapper_1, reducer_init=self.reducer_init_1, reducer=self.reducer_1),\n",
        "            MRStep(mapper_init=self.mapper_init_2, mapper=self.mapper_2)\n",
        "        ]\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    inputFile = \"/content/drive/MyDrive/BDP_Project/all_transactions.csv\"\n",
        "    outFile = \"/content/drive/MyDrive/BDP_Project/GLIST.csv\"\n",
        "    mr_job = ParallelCount1(args=[inputFile])\n",
        "    with mr_job.make_runner() as runner:\n",
        "      runner.run()\n",
        "      f = open(outFile, \"w\")\n",
        "      for key, value in mr_job.parse_output(runner.cat_output()):\n",
        "        s = f'{value}'\n",
        "        s = s[1:-2]\n",
        "        s = s.replace('[', '')\n",
        "        s = s.replace(\"'\", '')\n",
        "        print(s, file = f)\n",
        "      f.close()\n",
        "      print(\"Done!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ciJcbhTf1qeh",
        "outputId": "567a14e1-1485-4549-bb60-3cfec4d42cf7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting parallel_count.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python parallel_count.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D-tIpN6v2AtS",
        "outputId": "deb93f9d-6ce3-4ed1-e935-cbc87573f13f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No configs specified for inline runner\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Top K Most Recommended Items for each Product\n",
        "\n",
        "Here minimum support is taken as 10^-4 and the value of K is 100.\n",
        "\n",
        "The below given code, generates the Top K Most Recommended Items for each Product and stores it in an output file `topk.txt` in the same directory."
      ],
      "metadata": {
        "id": "t2XllCDYiyEK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%file parallel_fp.py\n",
        "import pandas as pd\n",
        "import heapq as heap\n",
        "from mrjob.job import MRJob\n",
        "from mrjob.step import MRStep\n",
        "from mlxtend.preprocessing import TransactionEncoder\n",
        "from mlxtend.frequent_patterns import fpgrowth\n",
        "\n",
        "tempFile = \"/content/drive/MyDrive/BDP_Project/GLIST.csv\"\n",
        "\n",
        "class ParallelFP(MRJob):\n",
        "\n",
        "    def mapper_init(self):\n",
        "      f = open(tempFile, 'r')\n",
        "      lines = f.readlines()\n",
        "      dep = {}\n",
        "      a=[]\n",
        "      for line in lines:\n",
        "        line=line[:-1]\n",
        "        record = line.split(',')\n",
        "        a=[]\n",
        "        for i in range(1,len(record)):\n",
        "          a.append(record[i])\n",
        "          a[-1]=a[-1][1:]\n",
        "        dep[record[0]]=a\n",
        "      self.dep = dep\n",
        "\n",
        "    def mapper(self, _, line):\n",
        "      record = line.split(\",\")\n",
        "      dep=self.dep\n",
        "      for x in range(len(record)):\n",
        "        a=[]\n",
        "        for i in dep:\n",
        "          if record[x] in dep[i]:\n",
        "            a.append(record[x])\n",
        "            for j in range(x+1,len(record)):\n",
        "              if record[j] in dep[i]:\n",
        "                a.append(record[j])\n",
        "            yield i,a\n",
        "\n",
        "    def reducer(self,item,vals):\n",
        "      x=[]\n",
        "      for i in vals:\n",
        "        x.append(i)\n",
        "      yield item,x\n",
        "\n",
        "    def reducer_1(self,item,vals):\n",
        "      for i in vals:\n",
        "        trans_encoder = TransactionEncoder() # Instanciate the encoder\n",
        "        trans_encoder_matrix = trans_encoder.fit(i).transform(i)\n",
        "        trans_encoder_matrix = pd.DataFrame(trans_encoder_matrix, columns=trans_encoder.columns_)\n",
        "        res=fpgrowth(trans_encoder_matrix,min_support=0.0001, use_colnames=True)\n",
        "        support = []\n",
        "        item_set = []\n",
        "        item_dict = {}\n",
        "        for i in res.index:\n",
        "          support.append(float(res['support'][i]))\n",
        "          item_set.append(list(res['itemsets'][i]))\n",
        "          item_dict[support[-1]]=item_set[-1]\n",
        "        yield item, item_dict\n",
        "\n",
        "    def mapper_init_2(self):\n",
        "      self.l=[]\n",
        "\n",
        "    def mapper_2(self,item,vals):\n",
        "      for i in vals:\n",
        "        heap.heappush(self.l,(float(i),vals[i]))\n",
        "        if(len(self.l)>100):\n",
        "          heap.heappop(self.l)\n",
        "\n",
        "    def mapper_final_2(self):\n",
        "      for i in self.l:\n",
        "        yield None, i\n",
        "\n",
        "    def reducer_init_2(self):\n",
        "        self.l=[]\n",
        "\n",
        "    def reducer_2(self,item,vals):\n",
        "      l1=self.l\n",
        "      for i in vals:\n",
        "        heap.heappush(l1,i)\n",
        "        if(len(l1)>100):\n",
        "          heap.heappop(l1)\n",
        "\n",
        "    def reducer_final_2(self):\n",
        "      self.l.sort(reverse=True)\n",
        "      for i in self.l:\n",
        "        yield  None,(i[0], i[1])\n",
        "\n",
        "    def mapper_init_3(self):\n",
        "      self.l=[]\n",
        "\n",
        "    def mapper_3(self,item,vals):\n",
        "      for i in range(len(vals[1])):\n",
        "        yield vals[1][i], vals\n",
        "\n",
        "    def reducer_3(self,item,vals):\n",
        "      for i in vals:\n",
        "        yield item,i\n",
        "\n",
        "    def steps(self):\n",
        "        return [\n",
        "            MRStep(mapper_init=self.mapper_init,mapper=self.mapper,reducer=self.reducer),\n",
        "            MRStep(reducer=self.reducer_1),\n",
        "            MRStep(mapper_init=self.mapper_init_2,mapper = self.mapper_2,mapper_final = self.mapper_final_2,reducer_init=self.reducer_init_2,reducer = self.reducer_2,reducer_final=self.reducer_final_2),\n",
        "            MRStep(mapper_init=self.mapper_init_3,mapper = self.mapper_3,reducer = self.reducer_3,)\n",
        "        ]\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    ParallelFP.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jnkwEpxYi0mq",
        "outputId": "efa6ab6e-6da9-415a-b52e-fde0f5d7e0c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing parallel_fp.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python parallel_fp.py \"/content/drive/MyDrive/BDP_Project/all_transactions.csv\" > \"/content/drive/MyDrive/BDP_Project/topk.txt\"\n",
        "# !python parallel_fp.py \"/content/drive/MyDrive/BDP_Project/all_transactions.csv\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gfGrdxFSrRlT",
        "outputId": "f85d1c98-0cab-4f95-a9b0-dde41f01e080"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No configs found; falling back on auto-configuration\n",
            "No configs specified for inline runner\n",
            "Creating temp directory /tmp/parallel_fp.root.20231123.053337.702791\n",
            "Running step 1 of 4...\n",
            "Running step 2 of 4...\n",
            "Running step 3 of 4...\n",
            "Running step 4 of 4...\n",
            "job output is in /tmp/parallel_fp.root.20231123.053337.702791/output\n",
            "Streaming final output from /tmp/parallel_fp.root.20231123.053337.702791/output...\n",
            "Removing temp directory /tmp/parallel_fp.root.20231123.053337.702791...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Parallel FP-Growth using Spark"
      ],
      "metadata": {
        "id": "GsDsfGQQnDLY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Installing and Setting up a Spark session"
      ],
      "metadata": {
        "id": "61lHdejDuOqF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --quiet pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IfrbP4V4n2Lg",
        "outputId": "dd37cd58-514a-4edd-e401-370001762342"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.9/316.9 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.fpm import FPGrowth\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.appName(\"FPGrowth\").getOrCreate()"
      ],
      "metadata": {
        "id": "-5nNOkqmnJXv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import Row\n",
        "\n",
        "data = [Row(id=i, items=x) for i, x in enumerate(all_transactions)]\n",
        "\n",
        "# Create a DataFrame\n",
        "df = spark.createDataFrame(data)\n",
        "\n",
        "# Show the DataFrame\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jqFfnx7npwd5",
        "outputId": "13a62bcc-1a37-4355-c1c7-963ae0ec262a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+--------------------+\n",
            "| id|               items|\n",
            "+---+--------------------+\n",
            "|  0|          [Hair Gel]|\n",
            "|  1|[Tuna, Bread, Tis...|\n",
            "|  2|[Jam, Soap, Ketchup]|\n",
            "|  3|         [BBQ Sauce]|\n",
            "|  4|[Hand Sanitizer, ...|\n",
            "|  5|[Shower Gel, Baby...|\n",
            "|  6|      [Cereal, Tuna]|\n",
            "|  7|[Iron, Extension ...|\n",
            "|  8|   [Banana, Pickles]|\n",
            "|  9|[Ketchup, Razors,...|\n",
            "| 10|      [Shrimp, Soda]|\n",
            "| 11|[Soap, Vacuum Cle...|\n",
            "| 12|[BBQ Sauce, Soda,...|\n",
            "| 13|[Ironing Board, L...|\n",
            "| 14|   [Lawn Mower, Tea]|\n",
            "| 15|             [Syrup]|\n",
            "| 16|[Tea, Spinach, Mu...|\n",
            "| 17|[Tuna, Bath Towel...|\n",
            "| 18|[Syrup, Yogurt, E...|\n",
            "| 19|              [Eggs]|\n",
            "+---+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Removing duplicate transactions (if any) present in the dataframe"
      ],
      "metadata": {
        "id": "XCSWJNy9ukW9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql.types import ArrayType, StringType\n",
        "\n",
        "# Define a UDF to remove duplicates from each transaction\n",
        "remove_duplicates_udf = udf(lambda row: list(set(row)), ArrayType(StringType()))\n",
        "\n",
        "# Remove duplicates from each transaction\n",
        "df = df.withColumn(\"items\", remove_duplicates_udf(df[\"items\"]))"
      ],
      "metadata": {
        "id": "X-az9JYms2sN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating a Spark FP Growth Model\n",
        "\n",
        "The following code gives the following 3 outputs:\n",
        "1. Frequency Table, showing the Frequency of each item in the dataset.\n",
        "2. Association Rules, showing the association rules generated by the FP-Growth model. Each rule has an “antecedent” (the items on the left-hand side of the rule), a “consequent” (the item on the right-hand side of the rule), and measures of rule interestingness such as “confidence” and “lift”.\n",
        "3. Prediction Table, which shows the items that the model predicts might be included in the transaction, based on the patterns it found in the data."
      ],
      "metadata": {
        "id": "JQSUXWMouxW1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fpGrowth = FPGrowth(itemsCol=\"items\", minSupport=0.0001, minConfidence=0.01)\n",
        "model = fpGrowth.fit(df)\n",
        "\n",
        "# Display frequent itemsets.\n",
        "model.freqItemsets.show()\n",
        "\n",
        "# Display generated association rules.\n",
        "model.associationRules.show()\n",
        "\n",
        "# transform examines the input items against all the association rules and summarize the\n",
        "# consequents as prediction\n",
        "model.transform(df).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6H-8WnwOrPhi",
        "outputId": "cd862ca8-caa7-42b2-ebd8-cdf88d887426"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+----+\n",
            "|               items|freq|\n",
            "+--------------------+----+\n",
            "|             [Apple]|1052|\n",
            "|[Apple, Light Bulbs]|  35|\n",
            "|[Apple, Light Bul...|   3|\n",
            "|    [Apple, Vinegar]|  32|\n",
            "|[Apple, Vinegar, ...|   3|\n",
            "|[Apple, Vinegar, ...|   3|\n",
            "|[Apple, Vinegar, ...|   4|\n",
            "|[Apple, Vinegar, ...|   3|\n",
            "|   [Apple, Tomatoes]|  26|\n",
            "|[Apple, Tomatoes,...|   3|\n",
            "|      [Apple, Honey]|  31|\n",
            "|[Apple, Honey, Ex...|   3|\n",
            "|[Apple, Honey, Yo...|   3|\n",
            "|[Apple, Honey, Ca...|   3|\n",
            "| [Apple, Toothbrush]|  31|\n",
            "|[Apple, Toothbrus...|   3|\n",
            "|[Apple, Toothbrus...|   4|\n",
            "|[Apple, Toothbrus...|   3|\n",
            "|[Apple, Toothbrus...|   4|\n",
            "|[Apple, Toothbrus...|   3|\n",
            "+--------------------+----+\n",
            "only showing top 20 rows\n",
            "\n",
            "+--------------------+-------------------+-------------------+------------------+--------------------+\n",
            "|          antecedent|         consequent|         confidence|              lift|             support|\n",
            "+--------------------+-------------------+-------------------+------------------+--------------------+\n",
            "|[Tea, Air Freshener]|        [Dish Soap]| 0.0967741935483871| 2.594482400761048|              1.0E-4|\n",
            "|[Tea, Air Freshener]|       [Trash Bags]| 0.0967741935483871|2.6273536709969343|              1.0E-4|\n",
            "|[Tea, Air Freshener]|        [Olive Oil]|0.12903225806451613|3.4256351698544103|1.333333333333333...|\n",
            "|[Tea, Air Freshener]|[Laundry Detergent]| 0.0967741935483871|2.6586316908897554|              1.0E-4|\n",
            "|[Tea, Air Freshener]|           [Cheese]| 0.0967741935483871|2.6981652476316107|              1.0E-4|\n",
            "|[Trash Cans, Toot...|            [Apple]|0.04477611940298507|1.2768855343056578|              1.0E-4|\n",
            "|[Trash Cans, Toot...|   [Vacuum Cleaner]|0.05970149253731343|1.7821341055914457|1.333333333333333...|\n",
            "|[Trash Cans, Toot...|    [Cleaning Rags]|0.05970149253731343|1.6754394538067379|1.333333333333333...|\n",
            "|[Trash Cans, Toot...|           [Orange]|0.07462686567164178|2.1863339552238803|1.666666666666666...|\n",
            "|[Trash Cans, Toot...|      [Canned Soup]|0.05970149253731343| 1.766316347257794|1.333333333333333...|\n",
            "|[Trash Cans, Toot...|          [Spinach]|0.05970149253731343|1.5878056525881232|1.333333333333333...|\n",
            "|[Trash Cans, Toot...|    [Air Freshener]|0.04477611940298507| 1.234635645302897|              1.0E-4|\n",
            "|[Trash Cans, Toot...|    [Ironing Board]|0.04477611940298507| 1.195092154883943|              1.0E-4|\n",
            "|[Trash Cans, Toot...|             [Milk]|0.04477611940298507|1.2357714646638014|              1.0E-4|\n",
            "|[Trash Cans, Toot...|           [Salmon]|0.04477611940298507|1.2211668928086838|              1.0E-4|\n",
            "|[Trash Cans, Toot...|           [Butter]|0.04477611940298507|1.1824679419802395|              1.0E-4|\n",
            "|[Trash Cans, Toot...|         [Hair Gel]|0.04477611940298507|1.2233912405187177|              1.0E-4|\n",
            "|[Trash Cans, Toot...|     [Toilet Paper]|0.04477611940298507|1.2301131704116777|              1.0E-4|\n",
            "|[Trash Cans, Toot...|             [Rice]|0.04477611940298507|1.2323702587977543|              1.0E-4|\n",
            "|[Trash Cans, Toot...| [Plant Fertilizer]|0.05970149253731343| 1.647695286218402|1.333333333333333...|\n",
            "+--------------------+-------------------+-------------------+------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "+---+--------------------+--------------------+\n",
            "| id|               items|          prediction|\n",
            "+---+--------------------+--------------------+\n",
            "|  0|          [Hair Gel]|[Apple, Honey, To...|\n",
            "|  1|[Trash Bags, Brea...|[Tea, Iron, Baby ...|\n",
            "|  2|[Ketchup, Jam, Soap]|[Tomatoes, Insect...|\n",
            "|  3|         [BBQ Sauce]|[Apple, Pasta, Va...|\n",
            "|  4|[Ice Cream, Exten...|[Baby Wipes, Spin...|\n",
            "|  5|[Baby Wipes, Pape...|[Apple, Pasta, Va...|\n",
            "|  6|      [Tuna, Cereal]|[Apple, Honey, To...|\n",
            "|  7|[Extension Cords,...|[Dish Soap, Soda,...|\n",
            "|  8|   [Pickles, Banana]|[Eggs, Air Freshe...|\n",
            "|  9|[Lawn Mower, Razo...|[Apple, Tomatoes,...|\n",
            "| 10|      [Shrimp, Soda]|[Apple, Honey, To...|\n",
            "| 11|[Mayonnaise, Soap...|[Apple, Tomatoes,...|\n",
            "| 12|[Lawn Mower, Soda...|[Apple, Tomatoes,...|\n",
            "| 13|[Laundry Detergen...|[Apple, Honey, To...|\n",
            "| 14|   [Lawn Mower, Tea]|[Apple, Tomatoes,...|\n",
            "| 15|             [Syrup]|[Apple, Pasta, Va...|\n",
            "| 16|[Cleaning Rags, T...|[Dish Soap, Dishw...|\n",
            "| 17|[Potatoes, Tuna, ...|[Water, Light Bul...|\n",
            "| 18|[Yogurt, Syrup, E...|[Tomatoes, Milk, ...|\n",
            "| 19|              [Eggs]|[Apple, Tomatoes,...|\n",
            "+---+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark.stop()"
      ],
      "metadata": {
        "id": "E9RKtBLurTyA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}